from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Optional
import os
import sys
from datetime import datetime
import logging
from openai import OpenAI
import json
import re
import hashlib
import time

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Decision Guide Bot")

# Simple in-memory cache for validation results
validation_cache = {}
CACHE_EXPIRY_SECONDS = 3600  # 1 hour

# Configuration
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)

# Request/Response models
class DocumentInfo(BaseModel):
    type: str  # 'text' or 'file'
    originalName: str
    size: int

class AnalyzeRequest(BaseModel):
    text: str
    documentInfo: DocumentInfo
    requestId: str

class CriteriaScore(BaseModel):
    criterion: str
    score: int  # 0-5 scale (will be converted to 1-10 in service)
    explanation: str
    reference_from_document: Optional[str] = None  # ×¦×™×˜×•×˜ ×ž×”×ž×¡×ž×š
    specific_improvement: Optional[str] = None  # ×”×¦×¢×” ×¡×¤×¦×™×¤×™×ª ×œ×©×™×¤×•×¨

class AnalyzeResponse(BaseModel):
    criteria_scores: List[CriteriaScore]
    recommendations: List[str]
    model_used: str
    misuse_detected: bool = False
    misuse_message: Optional[str] = None
    retry_status: Optional[str] = None

# Criteria definitions
CRITERIA = [
    "×œ×•×— ×–×ž× ×™× ×ž×—×™×™×‘",
    "×¦×•×•×ª ×ž×ª×›×œ×œ",
    "×’×•×¨× ×ž×ª×›×œ×œ ×™×—×™×“",
    "×ž× ×’× ×•×Ÿ ×“×™×•×•×—/×‘×§×¨×”",
    "×ž× ×’× ×•×Ÿ ×ž×“×™×“×” ×•×”×¢×¨×›×”",
    "×ž× ×’× ×•×Ÿ ×‘×™×§×•×¨×ª ×—×™×¦×•× ×™×ª",
    "×ž×©××‘×™× × ×“×¨×©×™×",
    "×ž×¢×•×¨×‘×•×ª ×©×œ ×ž×¡×¤×¨ ×“×¨×’×™× ×‘×ª×”×œ×™×š",
    "×ž×‘× ×” ×¡×¢×™×¤×™× ×•×—×œ×•×§×ª ×¢×‘×•×“×” ×‘×¨×•×¨×”",
    "×ž× ×’× ×•×Ÿ ×™×™×©×•× ×‘×©×˜×—",
    "×’×•×¨× ×ž×›×¨×™×¢",
    "×©×•×ª×¤×•×ª ×‘×™×Ÿ ×ž×’×–×¨×™×ª",
    "×ž×“×“×™ ×ª×•×¦××” ×•×ž×¨×›×™×‘×™ ×”×¦×œ×—×”"
]

def create_evaluation_prompt(text: str) -> str:
    """Create the evaluation prompt based on the eval_prompt.md specifications"""
    prompt = f"""
××ª×” ×ž×•×ž×—×” ×‘× ×™×ª×•×— ×”×—×œ×˜×•×ª ×ž×ž×©×œ×” ×‘×™×©×¨××œ. ×”×ž×˜×¨×” ×©×œ×š ×”×™× ×œ×¢×–×•×¨ ×œ×ž×©×ª×ž×©×™× ×œ×©×¤×¨ ××ª × ×™×¡×•×— ×”×—×œ×˜×•×ª ×”×ž×ž×©×œ×” ×©×œ×”×.

**×”× ×—×™×” ×—×©×•×‘×”**: ×¨×•×‘ ×”×ž×©×ª×ž×©×™× ×ž×©×ª×ž×©×™× ×‘×ž×¢×¨×›×ª ×‘×ª×•× ×œ×‘ ×•×ž×¢×œ×™× ×˜×™×•×˜×•×ª ×©×œ ×”×—×œ×˜×•×ª ×ž×ž×©×œ×” ××• ×ž×¡×ž×›×™ ×ž×“×™× ×™×•×ª. 
**×”×™×” × ×“×™×‘ ×•×ž×§×œ ×‘×”×’×“×¨×”** - ×× ×”×ž×¡×ž×š × ×¨××” ×›×ž×• ×˜×™×•×˜×”, ×”×¦×¢×”, ××• ×ž×¡×ž×š ×ž×“×™× ×™×•×ª ×›×œ×©×”×•, ×§×‘×œ ××•×ª×• ×œ× ×™×ª×•×—.

**×§×‘×œ ×œ× ×™×ª×•×—**:
- ×›×œ ×ž×¡×ž×š ×©×¢×•×¡×§ ×‘×ž×“×™× ×™×•×ª ×¦×™×‘×•×¨×™×ª
- ×˜×™×•×˜×•×ª ×•×”×¦×¢×•×ª (×’× ×× ×œ× ×ž×•×©×œ×ž×•×ª)
- ×ž×¡×ž×›×™ ×¢×‘×•×“×” ×ž×ž×©×œ×ª×™×™×
- ×”×¦×¢×•×ª ×—×•×§ ××• ×ª×§× ×•×ª
- ×ª×•×›× ×™×•×ª ×¢×‘×•×“×” ×©×œ ×ž×©×¨×“×™ ×ž×ž×©×œ×”
- ×›×œ ×ž×¡×ž×š ×©× ×¨××” ×§×©×•×¨ ×œ×¢×‘×•×“×” ×ž×ž×©×œ×ª×™×ª

**×“×—×” ×¨×§ ×‘×ž×§×¨×™× ×‘×¨×•×¨×™×**:
- ×›×¨×˜×™×¡×™ ×˜×™×¡×”
- ×§×•×¨×•×ª ×—×™×™× ××™×©×™×™×
- ×—×©×‘×•× ×™×•×ª ×•×§×‘×œ×•×ª
- ×ž×¡×ž×›×™× ×¨×¤×•××™×™× ××™×©×™×™×
- ×¡×¤×× ××• ×˜×§×¡×˜ ××§×¨××™

**×‘×¨×™×¨×ª ×ž×—×“×œ**: ×× ×™×© ×¡×¤×§, ×§×‘×œ ××ª ×”×ž×¡×ž×š ×œ× ×™×ª×•×— (is_government_decision: true).

×× ×–×• ×›×Ÿ ×”×—×œ×˜×ª ×ž×ž×©×œ×”, × ×ª×— ××•×ª×” ×œ×¤×™ 13 ×”×§×¨×™×˜×¨×™×•× ×™× ×”×‘××™×. ×œ×›×œ ×§×¨×™×˜×¨×™×•×Ÿ:
1. ×ª×Ÿ ×¦×™×•×Ÿ ×ž-0 ×¢×“ 5 (×”×™×” ×¢×§×‘×™ ×‘×¦×™×•× ×™× - ×”×©×ª×ž×© ×‘××•×ª× ×¡×˜× ×“×¨×˜×™× ×œ×›×œ ×”×¢×¨×›×”)
2. ×›×ª×•×‘ ×”×¡×‘×¨ ×§×¦×¨ (2-3 ×ž×©×¤×˜×™×)
3. ×¦×˜×˜ ××ª ×”×—×œ×§ ×”×¨×œ×•×•× ×˜×™ ×ž×”×ž×¡×ž×š (×× ×§×™×™×) - ×”×›× ×¡ ××ª ×”×¦×™×˜×•×˜ ×‘×©×“×” "reference_from_document"
4. ×ª×Ÿ ×”×¦×¢×” ×¡×¤×¦×™×¤×™×ª ××™×š ×œ×©×¤×¨ ××ª ×”× ×•×©× - ×”×›× ×¡ ××ª ×”×”×¦×¢×” ×‘×©×“×” "specific_improvement"

**×—×©×•×‘**: ×”×§×¨×™×˜×¨×™×•× ×™× ×”×—×©×•×‘×™× ×‘×™×•×ª×¨ ×”×:
- ×ž×©××‘×™× × ×“×¨×©×™× (×”×›×™ ×—×©×•×‘)
- ×œ×•×— ×–×ž× ×™× ×ž×—×™×™×‘ (×—×©×•×‘ ×ž××•×“)
- ×ž× ×’× ×•×Ÿ ×“×™×•×•×—/×‘×§×¨×”, ×ž×‘× ×” ×¡×¢×™×¤×™×, ×•×ž× ×’× ×•×Ÿ ×™×™×©×•× ×‘×©×˜×— (×—×©×•×‘×™×)
- ×©××¨ ×”×§×¨×™×˜×¨×™×•× ×™× ×¤×—×•×ª ×§×¨×™×˜×™×™× ××š ×¢×“×™×™×Ÿ ×—×©×•×‘×™×

**×—×©×•×‘ ×ž××•×“**: ×”×©×ª×ž×© ×‘×“×™×•×§ ×‘×©×ž×•×ª ×”×§×¨×™×˜×¨×™×•× ×™× ×›×¤×™ ×©×”× ×ž×•×¤×™×¢×™× ×œ×ž×˜×”, ×›×•×œ×œ ×”×ž×™×œ×™× "×‘×ª×”×œ×™×š" ×•"×‘×¨×•×¨×”" ×‘×ž×§×•× ×”×¨×œ×•×•× ×˜×™.

×”×˜×§×¡×˜ ×œ× ×™×ª×•×—:
{text}

×”×§×¨×™×˜×¨×™×•× ×™× ×œ× ×™×ª×•×—:

1. ×œ×•×— ×–×ž× ×™× ×ž×—×™×™×‘ (0-5):
   - 0: ××™×Ÿ ×©×•× ××–×›×•×¨ ×©×œ ×–×ž×Ÿ ×‘×™×¦×•×¢
   - 1: ××ž×™×¨×” ×›×œ×œ×™×ª ×›×ž×• "×‘×”×§×“×"
   - 2: ×ª××¨×™×š ××—×“ ×œ×¡×¢×™×£ ×©×•×œ×™
   - 3: ×–×ž× ×™× ×œ×¨×•×‘ ×”×¡×¢×™×¤×™× ××š ×œ× ×ž×—×™×™×‘×™×
   - 4: ×ª××¨×™×›×™× ×‘×¨×•×¨×™× ×œ×›×œ ×ž×©×™×ž×” ×¢×™×§×¨×™×ª
   - 5: ×ª××¨×™×›×™× ×ž×—×™×™×‘×™× ×¢× ×”×’×“×¨×ª ×”×©×œ×›×•×ª ×œ××™-×¢×ž×™×“×”

2. ×¦×•×•×ª ×ž×ª×›×œ×œ (0-5):
   - 0: ××™×Ÿ ×¦×•×•×ª ×ž×ª×›×œ×œ
   - 1: ××–×›×•×¨ ×ž×¢×•×¨×¤×œ ×œ×¦×•×•×ª ×¢×ª×™×“×™
   - 2: ×¦×•×•×ª ×ž×•×–×›×¨ ×œ×œ× ×¤×™×¨×•×˜
   - 3: ×¦×•×•×ª ×ž×•×’×“×¨ ××š ×œ×œ× ×¡×ž×›×•×™×•×ª ×‘×¨×•×¨×•×ª
   - 4: ×¦×•×•×ª ×ž×•×’×“×¨ ×¢× ×ž×©×ª×ª×¤×™× ×•××—×¨×™×•×ª
   - 5: ×¦×•×•×ª ×ž×¤×•×¨×˜ ×¢× ×¡×ž×›×•×™×•×ª, ×ª×“×™×¨×•×ª ×™×©×™×‘×•×ª, ×•×›×œ×œ×™ ×”×—×œ×˜×”

3. ×’×•×¨× ×ž×ª×›×œ×œ ×™×—×™×“ (0-5):
   - 0: ××™×Ÿ ×’×•×¨× ×™×—×™×“
   - 1: ×©×¨ ××—×¨××™ ×œ×œ× ×”×’×“×¨×ª ×ª×¤×§×™×“
   - 2: ×ž×ž×•× ×” ×ž×•×–×›×¨ ×œ×œ× ×‘×”×™×¨×•×ª
   - 3: ×™×•"×¨ ×•×¢×“×” ×œ×œ× ×¡×ž×›×•×ª ×ž×œ××”
   - 4: ×¨××© ×¤×¨×•×™×§×˜ ×¢× ××—×¨×™×•×ª ×œ×ª×›×œ×•×œ
   - 5: ×’×•×¨× ×ž×•×’×“×¨ ×¢× ×¡×ž×›×•×™×•×ª ×ž×œ××•×ª ×•×”×’×“×¨×ª ×ª×¤×§×™×“

4. ×ž× ×’× ×•×Ÿ ×“×™×•×•×—/×‘×§×¨×” (0-5):
   - 0: ××™×Ÿ ×“×™×•×•×—
   - 1: "×™×”×™×” ×¦×•×¨×š ×œ×¢×“×›×Ÿ"
   - 2: ×“×™×•×•×— ×œ×ž×™×©×”×• ×œ×œ× ×ª×“×™×¨×•×ª
   - 3: ×“×™×•×•×— ×ª×§×•×¤×ª×™ ×‘×¡×™×¡×™
   - 4: ×ž× ×’× ×•×Ÿ ×ž×¤×•×¨×˜ ×¢× ×ª×“×™×¨×•×ª ×•××—×¨××™×
   - 5: ×ž× ×’× ×•×Ÿ ×ž×•×‘× ×” ×¢× ×¤×•×¨×ž×˜, ×ª×“×™×¨×•×ª, ×•×˜×™×¤×•×œ ×‘×—×¨×™×’×•×ª

5. ×ž× ×’× ×•×Ÿ ×ž×“×™×“×” ×•×”×¢×¨×›×” (0-5):
   - 0: ××™×Ÿ ×ž×“×™×“×”
   - 1: "× ×‘×—×Ÿ ××ª ×”×”×©×¤×¢×”"
   - 2: ×›×•×•× ×” ×œ×ž×—×§×¨ ×œ×œ× ×¤×™×¨×•×˜
   - 3: ×ª×›× ×™×ª ×‘×¡×™×¡×™×ª ×œ×ž×“×™×“×”
   - 4: ×ž× ×’× ×•×Ÿ ×ž×¡×•×“×¨ ×¢× ×ª×“×™×¨×•×ª ×•×ž×“×“×™×
   - 5: ×ž×ª×•×•×” ×ž×œ× ×¢× ×ž×“×“×™×, ×œ×•"×–, ×•×’×•×£ ×ž×‘×¦×¢

6. ×ž× ×’× ×•×Ÿ ×‘×™×§×•×¨×ª ×—×™×¦×•× ×™×ª (0-5):
   - 0: ××™×Ÿ ×‘×™×§×•×¨×ª ×—×™×¦×•× ×™×ª
   - 1: "× ×©×§×•×œ ×ž×•×ž×—×™× ×—×™×¦×•× ×™×™×"
   - 2: ×’×•×£ ×—×™×¦×•× ×™ ×ž×•×–×›×¨ ×œ×œ× ×¤×™×¨×•×˜
   - 3: ×’×•×£ ×‘×™×§×•×¨×ª ×ž×•×’×“×¨ ×œ×œ× ×ª×”×œ×™×š
   - 4: ×’×•×£ ×—×™×¦×•× ×™ ×¢× ×ž×•×¢×“ ×”×¢×¨×›×”
   - 5: ×‘×™×§×•×¨×ª ×ž×¤×•×¨×˜×ª ×¢× ×ª×“×™×¨×•×ª ×•×¤×¨×¡×•×

7. ×ž×©××‘×™× × ×“×¨×©×™× (0-5):
   - 0: ××™×Ÿ ××–×›×•×¨ ×ž×©××‘×™×
   - 1: "×™×™×“×¨×© ×ª×§×¦×™×‘"
   - 2: ×¡×›×•× ×ž×•×–×›×¨ ×œ×œ× ×ž×§×•×¨
   - 3: ×¡×›×•× ×¢× ×ž×§×•×¨ ×œ× ×‘×¨×•×¨
   - 4: ×ª×§×¦×™×‘ ×¢× ×ž×§×•×¨ ×•×©×™×ž×•×© ×¢×™×§×¨×™
   - 5: ×¤×™×¨×•×˜ ×ž×œ× ×©×œ ×ª×§×¦×™×‘, ×›"×, ×•×ž×§×•×¨×•×ª

8. ×ž×¢×•×¨×‘×•×ª ×©×œ ×ž×¡×¤×¨ ×“×¨×’×™× ×‘×ª×”×œ×™×š (0-5):
   - 0: ×¨×§ ×“×¨×’ ××—×“
   - 1: ×’×•×£ × ×•×¡×£ ×œ×”×ª×™×™×¢×¦×•×ª
   - 2: ×¨×©×™×ž×ª ×“×¨×’×™× ×œ×œ× ×ª×™××•×
   - 3: ×“×¨×’×™× ×¢× ×¤×™×¨×•×˜ ×¢×§×¨×•× ×™
   - 4: ×ž×¢×•×¨×‘×•×ª ×ž×•×’×“×¨×ª ×©×œ ×›×ž×” ×“×¨×’×™×
   - 5: ×ª×™××•×¨ ×ž×œ× ×©×œ ×“×¨×’×™× ×•× ×”×œ×™ ×ª×™××•×

9. ×ž×‘× ×” ×¡×¢×™×¤×™× ×•×—×œ×•×§×ª ×¢×‘×•×“×” ×‘×¨×•×¨×” (0-5):
   - 0: ×˜×§×¡×˜ ×ž×‘×•×œ×’×Ÿ ×œ×œ× ×¡×¢×™×¤×™×
   - 1: ×¡×¢×™×¤×™× ×¢×ž×•×ž×™×
   - 2: ×—×œ×§ ×ž×”×¡×¢×™×¤×™× ×¢× ××—×¨×™×•×ª
   - 3: ×¨×•×‘ ×”×¡×¢×™×¤×™× ×¢× ××—×¨×™×•×ª
   - 4: ×¡×¢×™×¤×™× ×ž×¡×•×“×¨×™× ×¢× ××—×¨×™×•×ª
   - 5: ×ž×‘× ×” ×‘×¨×•×¨ ×¢× ×¡×¢×™×¤×™×, ××—×¨×™×•×ª, ×•××‘× ×™ ×“×¨×š

10. ×ž× ×’× ×•×Ÿ ×™×™×©×•× ×‘×©×˜×— (0-5):
    - 0: ××™×Ÿ ××–×›×•×¨ ×œ×™×™×©×•×
    - 1: "× ×™×™×©× ×“×¨×š ×¨×©×•×™×•×ª"
    - 2: ×ž× ×’× ×•×Ÿ ×›×œ×œ×™ ×œ×œ× ×¤×™×¨×•×˜
    - 3: ×ž× ×’× ×•×Ÿ ×‘×¡×™×¡×™ ×¢× ×’×•×£ ×ž×‘×¦×¢
    - 4: ×ž× ×’× ×•×Ÿ ×§×•× ×§×¨×˜×™ ×¢× ×™×—×™×“×•×ª ×œ×™×•×•×™
    - 5: ×ª×™××•×¨ ×©×œ× ×©×œ ××•×¤×Ÿ ×”×‘×™×¦×•×¢

11. ×’×•×¨× ×ž×›×¨×™×¢ (0-5):
    - 0: ××™×Ÿ ×’×•×¨× ×ž×›×¨×™×¢
    - 1: "×”×©×¨ ×¨×©××™ ×œ×”×—×œ×™×˜"
    - 2: "×•×¢×“×ª ×©×¨×™× ×ª×“×•×Ÿ"
    - 3: ×’×•×¨× ×ž×›×¨×™×¢ ×œ×œ× ×ª×”×œ×™×š
    - 4: ×’×•×¨× ×ž×›×¨×™×¢ ×‘×¨×•×¨
    - 5: ×’×•×¨× ×ž×›×¨×™×¢ ×¢× ×ª×”×œ×™×š ×ž×¤×•×¨×˜

12. ×©×•×ª×¤×•×ª ×‘×™×Ÿ ×ž×’×–×¨×™×ª (0-5):
    - 0: ××™×Ÿ ×©×•×ª×¤×•×ª
    - 1: "× ×©×§×•×œ ×œ×©×ª×£"
    - 2: ××¨×’×•×Ÿ ×ž×•×–×›×¨ ×œ×œ× ×ª×¤×§×™×“
    - 3: ×ž×’×–×¨×™× ×©×•×ª×¤×™× ×œ×œ× ×ž× ×“×˜
    - 4: ×¤×™×¨×•×˜ ×¢×œ ×©×•×ª×¤×™× ×•××•×¤×Ÿ ×¢×‘×•×“×”
    - 5: ×©×™×ª×•×£ ×ž×¤×•×¨×˜ ×¢× ×ª×¤×§×™×“×™× ×•×ž×™×ž×•×Ÿ

13. ×ž×“×“×™ ×ª×•×¦××” ×•×ž×¨×›×™×‘×™ ×”×¦×œ×—×” (0-5):
    - 0: ×¨×§ ×¤×¢×•×œ×•×ª ×œ×œ× ×™×¢×“×™×
    - 1: "× ×©××£ ×œ×©×™×¤×•×¨"
    - 2: ×™×¢×“ ×›×œ×œ×™ ×œ×œ× ×ž×¡×¤×¨×™×
    - 3: ×™×¢×“ ×ž×¡×¤×¨×™ ×œ×œ× ×–×ž×Ÿ
    - 4: ×™×¢×“ ×›×ž×•×ª×™ ×¢× ×–×ž×Ÿ
    - 5: ×™×¢×“×™× ×ž×¡×¤×¨×™×™× ×¢× ×ž×ª×•×“×•×œ×•×’×™×”

**×—×©×•×‘**: ×× ×”×ž×¡×ž×š ××™× ×• ×”×—×œ×˜×ª ×ž×ž×©×œ×” ××• ×˜×™×•×˜×” ×©×œ ×”×—×œ×˜×ª ×ž×ž×©×œ×”, ××œ ×ª× ×ª×— ××•×ª×• ×œ×¤×™ ×”×§×¨×™×˜×¨×™×•× ×™×. ×‘×ž×§×•× ×–××ª, ×”×—×–×¨:
{{
    "is_government_decision": false,
    "criteria_scores": [],
    "recommendations": [],
    "misuse_message": "×ž×¦×˜×¢×¨, ×× ×™ ×ž×™×•×¢×“ ××š ×•×¨×§ ×œ× ×™×ª×•×— ×˜×™×•×˜×•×ª ×©×œ ×”×—×œ×˜×•×ª ×ž×ž×©×œ×”. ×”×ž×¡×ž×š ×©×”×¢×œ×™×ª × ×¨××” ×›×ž×• [×¡×•×’ ×”×ž×¡×ž×š]. ×× ×‘×¨×¦×•× ×š ×œ× ×ª×— ×˜×™×•×˜×ª ×”×—×œ×˜×ª ×ž×ž×©×œ×”, ×× × ×”×¢×œ×” ××• ×”×“×‘×§ ××ª ×”×˜×§×¡×˜ ×”×ž×œ× ×©×œ ×”×˜×™×•×˜×”."
}}

×× ×–×• ×›×Ÿ ×”×—×œ×˜×ª ×ž×ž×©×œ×”, ×”×—×–×¨ ××ª ×”×ª×©×•×‘×” ×‘×¤×•×¨×ž×˜ JSON ×”×‘×:
{{
    "is_government_decision": true,
    "criteria_scores": [
        {{
            "criterion": "×©× ×”×§×¨×™×˜×¨×™×•×Ÿ",
            "score": 0-5,
            "explanation": "×”×¡×‘×¨ ×§×¦×¨",
            "reference_from_document": "×¦×™×˜×•×˜ ×¨×œ×•×•× ×˜×™ ×ž×”×ž×¡×ž×š (×× ×§×™×™×)",
            "specific_improvement": "×”×¦×¢×” ×¡×¤×¦×™×¤×™×ª ×œ×©×™×¤×•×¨"
        }}
    ],
    "recommendations": ["×”×ž×œ×¦×” 1", "×”×ž×œ×¦×” 2", ...],
    "misuse_message": null
}}
"""
    return prompt

def detect_misuse(response_json: dict) -> tuple[bool, Optional[str]]:
    """Detect if the user is trying to misuse the bot"""
    if not response_json.get("is_government_decision", True):
        # Get the GPT's explanation if available
        gpt_message = response_json.get("misuse_message", "")
        
        # Extract what type of document GPT detected
        doc_type_match = re.search(r'× ×¨××” ×›×ž×•\s*([^\.]+)', gpt_message)
        detected_type = doc_type_match.group(1) if doc_type_match else "×ž×¡×ž×š ×œ× ×ž×–×•×”×”"
        
        # Create a more informative error message
        enhanced_message = f"""âš ï¸ **×©×™×ž×•×© ×œ× ×ª×§×™×Ÿ**

×ž×¦×˜×¢×¨, ×× ×™ ×ž×™×•×¢×“ ××š ×•×¨×§ ×œ× ×™×ª×•×— ×˜×™×•×˜×•×ª ×©×œ ×”×—×œ×˜×•×ª ×ž×ž×©×œ×”.

×”×ž×¡×ž×š ×©×”×¢×œ×™×ª × ×¨××” ×›×ž×• **{detected_type}** ×•×œ× ×ž×•×‘× ×” ×›×”×—×œ×˜×ª ×ž×ž×©×œ×”.

×× ×‘×¨×¦×•× ×š ×œ× ×ª×— ×˜×™×•×˜×ª ×”×—×œ×˜×ª ×ž×ž×©×œ×”, ×× × ×”×¢×œ×” ××• ×”×“×‘×§ ××ª ×”×˜×§×¡×˜ ×”×ž×œ× ×©×œ ×”×˜×™×•×˜×”.

ðŸ’¡ **×˜×™×¤**: ×”×—×œ×˜×ª ×ž×ž×©×œ×” ×¦×¨×™×›×” ×œ×›×œ×•×œ:
â€¢ ×›×•×ª×¨×ª ×¢× × ×•×©× ×ž×“×™× ×™×•×ª
â€¢ ××–×›×•×¨ ×©×œ ×ž×©×¨×“×™ ×ž×ž×©×œ×” ××• ×©×¨×™×
â€¢ ×¡×¢×™×¤×™× ×”×ž×ª××¨×™× ×¤×¢×•×œ×•×ª ×ž×ž×©×œ×ª×™×•×ª
â€¢ ×©×¤×” ×¤×•×¨×ž×œ×™×ª ×©×œ ×ž×¡×ž×š ×ž×ž×©×œ×ª×™"""
        
        return True, enhanced_message
    return False, None

def perform_analysis(response_json: dict, model: str, doc_hash: str) -> AnalyzeResponse:
    """Perform the actual analysis of the document after validation"""
    try:
        # Extract criteria scores
        criteria_scores = []
        for score_data in response_json.get("criteria_scores", []):
            criteria_scores.append(CriteriaScore(
                criterion=score_data["criterion"],
                score=score_data["score"],
                explanation=score_data["explanation"],
                reference_from_document=score_data.get("reference_from_document"),
                specific_improvement=score_data.get("specific_improvement")
            ))
        
        # Extract recommendations
        recommendations = response_json.get("recommendations", [])
        
        # Generate additional recommendations based on low scores
        for score in criteria_scores:
            if score.score <= 2:
                if score.criterion == "×œ×•×— ×–×ž× ×™× ×ž×—×™×™×‘":
                    recommendations.append("×™×© ×œ×”×•×¡×™×£ ×ª××¨×™×›×™ ×™×¢×“ ×ž×—×™×™×‘×™× ×œ×›×œ ×ž×©×™×ž×” ×¢×™×§×¨×™×ª ×‘×”×—×œ×˜×”")
                elif score.criterion == "×ž× ×’× ×•×Ÿ ×‘×™×§×•×¨×ª ×—×™×¦×•× ×™×ª":
                    recommendations.append("×ž×•×ž×œ×¥ ×œ×”×•×¡×™×£ ×ž× ×’× ×•×Ÿ ×‘×™×§×•×¨×ª ×—×™×¦×•× ×™×ª ×œ×•×•×“× ×™×™×©×•× ××¤×§×˜×™×‘×™")
                elif score.criterion == "×ž×“×“×™ ×ª×•×¦××” ×•×ž×¨×›×™×‘×™ ×”×¦×œ×—×”":
                    recommendations.append("×™×© ×œ×”×’×“×™×¨ ×ž×“×“×™ ×”×¦×œ×—×” ×›×ž×•×ª×™×™× ×•×‘×¨×•×¨×™× ×¢× ×™×¢×“×™× ×ž×¡×¤×¨×™×™×")
        
        return AnalyzeResponse(
            criteria_scores=criteria_scores,
            recommendations=recommendations[:5],  # Limit to top 5 recommendations
            model_used=model,
            misuse_detected=False
        )
    except KeyError as e:
        logger.error(f"Missing required field in analysis for doc_hash {doc_hash}: {str(e)}")
        raise
    except Exception as e:
        logger.error(f"Error during analysis for doc_hash {doc_hash}: {str(e)}")
        raise

def perform_analysis_with_retries(response_json: dict, model: str, doc_hash: str, request_id: str) -> AnalyzeResponse:
    """Perform analysis with retry logic"""
    MAX_RETRIES = 3
    
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            logger.info(f"Analysis attempt {attempt} for doc_hash {doc_hash}, request_id {request_id}")
            result = perform_analysis(response_json, model, doc_hash)
            
            if attempt > 1:
                result.retry_status = f"×”× ×™×ª×•×— ×”×¦×œ×™×— ×‘× ×™×¡×™×•×Ÿ {attempt}"
                logger.info(f"Analysis succeeded on attempt {attempt} for doc_hash {doc_hash}")
            
            return result
            
        except Exception as e:
            logger.warning(f"Analysis attempt {attempt} failed for doc_hash {doc_hash}: {str(e)}")
            
            if attempt < MAX_RETRIES:
                # Calculate wait time with exponential backoff
                wait_time = attempt * 1.5  # 1.5s, 3s
                logger.info(f"Waiting {wait_time}s before retry {attempt + 1} for doc_hash {doc_hash}")
                time.sleep(wait_time)
                continue
            else:
                # All retries exhausted
                logger.error(f"All {MAX_RETRIES} analysis attempts failed for doc_hash {doc_hash}")
                return AnalyzeResponse(
                    criteria_scores=[],
                    recommendations=[f"×”× ×™×ª×•×— × ×›×©×œ ×œ××—×¨ {MAX_RETRIES} × ×™×¡×™×•× ×•×ª. ×× × × ×¡×” ×©×•×‘ ×ž××•×—×¨ ×™×•×ª×¨."],
                    model_used=model,
                    misuse_detected=False,
                    retry_status=f"× ×›×©×œ ×œ××—×¨ {MAX_RETRIES} × ×™×¡×™×•× ×•×ª"
                )

@app.post("/analyze", response_model=AnalyzeResponse)
async def analyze_decision(request: AnalyzeRequest):
    """Analyze a government decision draft against 13 criteria"""
    try:
        # Calculate document hash for tracking
        doc_hash = hashlib.md5(request.text.encode()).hexdigest()
        
        # Log the request with hash
        logger.info(f"Analyzing decision draft - text_length: {len(request.text)}, request_id: {request.requestId}, doc_hash: {doc_hash}")
        
        # Check cache for previous validation result
        cache_key = f"validation_{doc_hash}"
        cached_result = validation_cache.get(cache_key)
        if cached_result:
            cache_timestamp, is_valid, rejection_reason = cached_result
            if (datetime.utcnow() - cache_timestamp).total_seconds() < CACHE_EXPIRY_SECONDS:
                logger.info(f"Using cached validation result - doc_hash: {doc_hash}, is_valid: {is_valid}")
                if not is_valid:
                    return AnalyzeResponse(
                        criteria_scores=[],
                        recommendations=[],
                        model_used="cached",
                        misuse_detected=True,
                        misuse_message=rejection_reason
                    )
        
        # Always use GPT-4 for better accuracy in document classification
        model = "gpt-4o"
        
        # Create the evaluation prompt
        prompt = create_evaluation_prompt(request.text)
        
        # Call OpenAI API
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": """××ª×” ×ž×•×ž×—×” ×‘× ×™×ª×•×— ×”×—×œ×˜×•×ª ×ž×ž×©×œ×” ×‘×™×©×¨××œ. 
×”× ×—×™×” ×—×©×•×‘×”: ×¨×•×‘ ×”×ž×©×ª×ž×©×™× ×ž×¢×œ×™× ×ž×¡×ž×›×™× ×œ×’×™×˜×™×ž×™×™×. ×”×™×” × ×“×™×‘ ×•×ž×§×œ ×‘×§×‘×œ×ª ×ž×¡×ž×›×™× ×œ× ×™×ª×•×—.
×§×‘×œ ×›×œ ×ž×¡×ž×š ×©× ×¨××” ×§×©×•×¨ ×œ×ž×“×™× ×™×•×ª ×¦×™×‘×•×¨×™×ª, ×˜×™×•×˜×•×ª, ×”×¦×¢×•×ª, ××• ×¢×‘×•×“×” ×ž×ž×©×œ×ª×™×ª.
×“×—×” ×¨×§ ×ž×¡×ž×›×™× ×‘×¨×•×¨×™× ×›×ž×• ×›×¨×˜×™×¡×™ ×˜×™×¡×”, ×§×•×¨×•×ª ×—×™×™× ××™×©×™×™×, ××• ×—×©×‘×•× ×™×•×ª.
×‘×¨×™×¨×ª ×ž×—×“×œ: ×× ×™×© ×¡×¤×§ - ×§×‘×œ ××ª ×”×ž×¡×ž×š (is_government_decision: true).
×ª×ž×™×“ ×”×—×–×¨ ×ª×©×•×‘×•×ª ×‘×¤×•×¨×ž×˜ JSON ×ª×§×™×Ÿ."""},
                {"role": "user", "content": prompt}
            ],
            temperature=0.0,  # Set to 0 for consistent scoring
            max_tokens=3000
        )
        
        # Parse the response
        response_text = response.choices[0].message.content
        
        # Extract JSON from the response
        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
        if json_match:
            response_json = json.loads(json_match.group())
        else:
            logger.error(f"Failed to extract JSON from GPT response for doc_hash: {doc_hash}")
            raise ValueError("Failed to extract JSON from response")
        
        # Log the validation result
        is_gov_decision = response_json.get("is_government_decision", True)
        logger.info(f"Document validation - doc_hash: {doc_hash}, is_government_decision: {is_gov_decision}")
        
        # Check for misuse
        misuse_detected, misuse_message = detect_misuse(response_json)
        
        # Cache the validation result
        validation_cache[cache_key] = (datetime.utcnow(), not misuse_detected, misuse_message)
        
        if misuse_detected:
            logger.warning(f"Document rejected - doc_hash: {doc_hash}, reason: {misuse_message}")
            return AnalyzeResponse(
                criteria_scores=[],
                recommendations=[],
                model_used=model,
                misuse_detected=True,
                misuse_message=misuse_message
            )
        
        # Log token usage
        if hasattr(response, 'usage'):
            logger.info(f"Token usage - Model: {model}, Prompt: {response.usage.prompt_tokens}, "
                       f"Completion: {response.usage.completion_tokens}, "
                       f"Total: {response.usage.total_tokens}")
        
        # Document passed validation - now perform analysis with retries
        logger.info(f"Document passed validation, starting analysis for doc_hash: {doc_hash}")
        return perform_analysis_with_retries(response_json, model, doc_hash, request.requestId)
        
    except json.JSONDecodeError as e:
        logger.error(f"JSON parsing error for doc_hash {doc_hash}: {str(e)}")
        # Try to be more resilient - assume it's a valid government document if parsing failed
        return AnalyzeResponse(
            criteria_scores=[],
            recommendations=["×œ× × ×™×ª×Ÿ ×œ×¤×¢× ×— ××ª ×ª×’×•×‘×ª ×”×ž×¢×¨×›×ª. ×× × × ×¡×” ×©×•×‘."],
            model_used=model,
            misuse_detected=False
        )
    except Exception as e:
        logger.error(f"Error analyzing decision for doc_hash {doc_hash}: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "service": "Decision Guide Bot",
        "timestamp": datetime.utcnow().isoformat()
    }

@app.post("/clear-cache")
async def clear_cache():
    """Clear the validation cache - useful for testing"""
    global validation_cache
    cache_size = len(validation_cache)
    validation_cache.clear()
    logger.info(f"Cleared validation cache - removed {cache_size} entries")
    return {"status": "cache cleared", "entries_removed": cache_size}

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", "8018"))
    uvicorn.run(app, host="0.0.0.0", port=port)