from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Optional
import os
import sys
from datetime import datetime
import logging
from openai import OpenAI
import json
import re
import hashlib

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Decision Guide Bot")

# Simple in-memory cache for validation results
validation_cache = {}
CACHE_EXPIRY_SECONDS = 3600  # 1 hour

# Configuration
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)

# Request/Response models
class DocumentInfo(BaseModel):
    type: str  # 'text' or 'file'
    originalName: str
    size: int

class AnalyzeRequest(BaseModel):
    text: str
    documentInfo: DocumentInfo
    requestId: str

class CriteriaScore(BaseModel):
    criterion: str
    score: int  # 0-5 scale (will be converted to 1-10 in service)
    explanation: str
    reference_from_document: Optional[str] = None  # ×¦×™×˜×•×˜ ××”××¡××š
    specific_improvement: Optional[str] = None  # ×”×¦×¢×” ×¡×¤×¦×™×¤×™×ª ×œ×©×™×¤×•×¨

class AnalyzeResponse(BaseModel):
    criteria_scores: List[CriteriaScore]
    recommendations: List[str]
    model_used: str
    misuse_detected: bool = False
    misuse_message: Optional[str] = None

# Criteria definitions
CRITERIA = [
    "×œ×•×— ×–×× ×™× ××—×™×™×‘",
    "×¦×•×•×ª ××ª×›×œ×œ",
    "×’×•×¨× ××ª×›×œ×œ ×™×—×™×“",
    "×× ×’× ×•×Ÿ ×“×™×•×•×—/×‘×§×¨×”",
    "×× ×’× ×•×Ÿ ××“×™×“×” ×•×”×¢×¨×›×”",
    "×× ×’× ×•×Ÿ ×‘×™×§×•×¨×ª ×—×™×¦×•× ×™×ª",
    "××©××‘×™× × ×“×¨×©×™×",
    "××¢×•×¨×‘×•×ª ×©×œ ××¡×¤×¨ ×“×¨×’×™× ×‘×ª×”×œ×™×š",
    "××‘× ×” ×¡×¢×™×¤×™× ×•×—×œ×•×§×ª ×¢×‘×•×“×” ×‘×¨×•×¨×”",
    "×× ×’× ×•×Ÿ ×™×™×©×•× ×‘×©×˜×—",
    "×’×•×¨× ××›×¨×™×¢",
    "×©×•×ª×¤×•×ª ×‘×™×Ÿ ××’×–×¨×™×ª",
    "××“×“×™ ×ª×•×¦××” ×•××¨×›×™×‘×™ ×”×¦×œ×—×”"
]

def create_evaluation_prompt(text: str) -> str:
    """Create the evaluation prompt based on the eval_prompt.md specifications"""
    prompt = f"""
××ª×” ××•××—×” ×‘× ×™×ª×•×— ×”×—×œ×˜×•×ª ×××©×œ×” ×‘×™×©×¨××œ. ×”××˜×¨×” ×©×œ×š ×”×™× ×œ×¢×–×•×¨ ×œ××©×ª××©×™× ×œ×©×¤×¨ ××ª × ×™×¡×•×— ×”×—×œ×˜×•×ª ×”×××©×œ×” ×©×œ×”×.

**×—×©×•×‘ ×××•×“ - ×‘×“×™×§×” ×¨××©×•× ×™×ª**: 
×¨××©×™×ª, ×¢×œ×™×š ×œ×‘×“×•×§ ×”×× ×”×˜×§×¡×˜ ×©×”×ª×§×‘×œ ×”×•× ××›×Ÿ ×˜×™×•×˜×ª ×”×—×œ×˜×ª ×××©×œ×” ××• ××¡××š ×“×•××” (×›××• ×”×¦×¢×ª ××“×™× ×™×•×ª ×××©×œ×ª×™×ª).

×¡×™×× ×™× ×œ×–×™×”×•×™ ×”×—×œ×˜×ª ×××©×œ×”:
- ×›×•×ª×¨×ª ×¢× ××¡×¤×¨ ×”×—×œ×˜×” ××• × ×•×©× ××“×™× ×™×•×ª
- ××–×›×•×¨ ×©×œ ××©×¨×“×™ ×××©×œ×”, ×©×¨×™×, ××• ×’×•×¤×™× ×××©×œ×ª×™×™×
- ×¡×¢×™×¤×™× ×”××ª××¨×™× ×¤×¢×•×œ×•×ª ××• ×”×—×œ×˜×•×ª ×××©×œ×ª×™×•×ª
- ×©×¤×” ×¤×•×¨××œ×™×ª ×©×œ ××¡××š ×××©×œ×ª×™
- ×ª×›× ×™× ×”×§×©×•×¨×™× ×œ××“×™× ×™×•×ª ×¦×™×‘×•×¨×™×ª

×“×•×’×××•×ª ×œ××¡××›×™× ×©××™× × ×”×—×œ×˜×•×ª ×××©×œ×”:
- ×›×¨×˜×™×¡×™ ×˜×™×¡×”
- ×§×•×¨×•×ª ×—×™×™×
- ×—×©×‘×•× ×™×•×ª
- ××¡××›×™× ××™×©×™×™×
- ×“×•×—×•×ª ×¤×™× × ×¡×™×™× ×¤×¨×˜×™×™×
- ××¡××›×™× ×¨×¤×•××™×™×
- ×—×•×–×™× ×¤×¨×˜×™×™×

×× ×”××¡××š ××™× ×• ×”×—×œ×˜×ª ×××©×œ×”, ×”×—×–×¨ is_government_decision: false ×¢× ×”×¡×‘×¨ ××ª××™×.

×× ×–×• ×›×Ÿ ×”×—×œ×˜×ª ×××©×œ×”, × ×ª×— ××•×ª×” ×œ×¤×™ 13 ×”×§×¨×™×˜×¨×™×•× ×™× ×”×‘××™×. ×œ×›×œ ×§×¨×™×˜×¨×™×•×Ÿ:
1. ×ª×Ÿ ×¦×™×•×Ÿ ×-0 ×¢×“ 5 (×”×™×” ×¢×§×‘×™ ×‘×¦×™×•× ×™× - ×”×©×ª××© ×‘××•×ª× ×¡×˜× ×“×¨×˜×™× ×œ×›×œ ×”×¢×¨×›×”)
2. ×›×ª×•×‘ ×”×¡×‘×¨ ×§×¦×¨ (2-3 ××©×¤×˜×™×)
3. ×¦×˜×˜ ××ª ×”×—×œ×§ ×”×¨×œ×•×•× ×˜×™ ××”××¡××š (×× ×§×™×™×) - ×”×›× ×¡ ××ª ×”×¦×™×˜×•×˜ ×‘×©×“×” "reference_from_document"
4. ×ª×Ÿ ×”×¦×¢×” ×¡×¤×¦×™×¤×™×ª ××™×š ×œ×©×¤×¨ ××ª ×”× ×•×©× - ×”×›× ×¡ ××ª ×”×”×¦×¢×” ×‘×©×“×” "specific_improvement"

**×—×©×•×‘**: ×”×§×¨×™×˜×¨×™×•× ×™× ×”×—×©×•×‘×™× ×‘×™×•×ª×¨ ×”×:
- ××©××‘×™× × ×“×¨×©×™× (×”×›×™ ×—×©×•×‘)
- ×œ×•×— ×–×× ×™× ××—×™×™×‘ (×—×©×•×‘ ×××•×“)
- ×× ×’× ×•×Ÿ ×“×™×•×•×—/×‘×§×¨×”, ××‘× ×” ×¡×¢×™×¤×™×, ×•×× ×’× ×•×Ÿ ×™×™×©×•× ×‘×©×˜×— (×—×©×•×‘×™×)
- ×©××¨ ×”×§×¨×™×˜×¨×™×•× ×™× ×¤×—×•×ª ×§×¨×™×˜×™×™× ××š ×¢×“×™×™×Ÿ ×—×©×•×‘×™×

**×—×©×•×‘ ×××•×“**: ×”×©×ª××© ×‘×“×™×•×§ ×‘×©××•×ª ×”×§×¨×™×˜×¨×™×•× ×™× ×›×¤×™ ×©×”× ××•×¤×™×¢×™× ×œ××˜×”, ×›×•×œ×œ ×”××™×œ×™× "×‘×ª×”×œ×™×š" ×•"×‘×¨×•×¨×”" ×‘××§×•× ×”×¨×œ×•×•× ×˜×™.

×”×˜×§×¡×˜ ×œ× ×™×ª×•×—:
{text}

×”×§×¨×™×˜×¨×™×•× ×™× ×œ× ×™×ª×•×—:

1. ×œ×•×— ×–×× ×™× ××—×™×™×‘ (0-5):
   - 0: ××™×Ÿ ×©×•× ××–×›×•×¨ ×©×œ ×–××Ÿ ×‘×™×¦×•×¢
   - 1: ×××™×¨×” ×›×œ×œ×™×ª ×›××• "×‘×”×§×“×"
   - 2: ×ª××¨×™×š ××—×“ ×œ×¡×¢×™×£ ×©×•×œ×™
   - 3: ×–×× ×™× ×œ×¨×•×‘ ×”×¡×¢×™×¤×™× ××š ×œ× ××—×™×™×‘×™×
   - 4: ×ª××¨×™×›×™× ×‘×¨×•×¨×™× ×œ×›×œ ××©×™××” ×¢×™×§×¨×™×ª
   - 5: ×ª××¨×™×›×™× ××—×™×™×‘×™× ×¢× ×”×’×“×¨×ª ×”×©×œ×›×•×ª ×œ××™-×¢××™×“×”

2. ×¦×•×•×ª ××ª×›×œ×œ (0-5):
   - 0: ××™×Ÿ ×¦×•×•×ª ××ª×›×œ×œ
   - 1: ××–×›×•×¨ ××¢×•×¨×¤×œ ×œ×¦×•×•×ª ×¢×ª×™×“×™
   - 2: ×¦×•×•×ª ××•×–×›×¨ ×œ×œ× ×¤×™×¨×•×˜
   - 3: ×¦×•×•×ª ××•×’×“×¨ ××š ×œ×œ× ×¡××›×•×™×•×ª ×‘×¨×•×¨×•×ª
   - 4: ×¦×•×•×ª ××•×’×“×¨ ×¢× ××©×ª×ª×¤×™× ×•××—×¨×™×•×ª
   - 5: ×¦×•×•×ª ××¤×•×¨×˜ ×¢× ×¡××›×•×™×•×ª, ×ª×“×™×¨×•×ª ×™×©×™×‘×•×ª, ×•×›×œ×œ×™ ×”×—×œ×˜×”

3. ×’×•×¨× ××ª×›×œ×œ ×™×—×™×“ (0-5):
   - 0: ××™×Ÿ ×’×•×¨× ×™×—×™×“
   - 1: ×©×¨ ××—×¨××™ ×œ×œ× ×”×’×“×¨×ª ×ª×¤×§×™×“
   - 2: ×××•× ×” ××•×–×›×¨ ×œ×œ× ×‘×”×™×¨×•×ª
   - 3: ×™×•"×¨ ×•×¢×“×” ×œ×œ× ×¡××›×•×ª ××œ××”
   - 4: ×¨××© ×¤×¨×•×™×§×˜ ×¢× ××—×¨×™×•×ª ×œ×ª×›×œ×•×œ
   - 5: ×’×•×¨× ××•×’×“×¨ ×¢× ×¡××›×•×™×•×ª ××œ××•×ª ×•×”×’×“×¨×ª ×ª×¤×§×™×“

4. ×× ×’× ×•×Ÿ ×“×™×•×•×—/×‘×§×¨×” (0-5):
   - 0: ××™×Ÿ ×“×™×•×•×—
   - 1: "×™×”×™×” ×¦×•×¨×š ×œ×¢×“×›×Ÿ"
   - 2: ×“×™×•×•×— ×œ××™×©×”×• ×œ×œ× ×ª×“×™×¨×•×ª
   - 3: ×“×™×•×•×— ×ª×§×•×¤×ª×™ ×‘×¡×™×¡×™
   - 4: ×× ×’× ×•×Ÿ ××¤×•×¨×˜ ×¢× ×ª×“×™×¨×•×ª ×•××—×¨××™×
   - 5: ×× ×’× ×•×Ÿ ××•×‘× ×” ×¢× ×¤×•×¨××˜, ×ª×“×™×¨×•×ª, ×•×˜×™×¤×•×œ ×‘×—×¨×™×’×•×ª

5. ×× ×’× ×•×Ÿ ××“×™×“×” ×•×”×¢×¨×›×” (0-5):
   - 0: ××™×Ÿ ××“×™×“×”
   - 1: "× ×‘×—×Ÿ ××ª ×”×”×©×¤×¢×”"
   - 2: ×›×•×•× ×” ×œ××—×§×¨ ×œ×œ× ×¤×™×¨×•×˜
   - 3: ×ª×›× ×™×ª ×‘×¡×™×¡×™×ª ×œ××“×™×“×”
   - 4: ×× ×’× ×•×Ÿ ××¡×•×“×¨ ×¢× ×ª×“×™×¨×•×ª ×•××“×“×™×
   - 5: ××ª×•×•×” ××œ× ×¢× ××“×“×™×, ×œ×•"×–, ×•×’×•×£ ××‘×¦×¢

6. ×× ×’× ×•×Ÿ ×‘×™×§×•×¨×ª ×—×™×¦×•× ×™×ª (0-5):
   - 0: ××™×Ÿ ×‘×™×§×•×¨×ª ×—×™×¦×•× ×™×ª
   - 1: "× ×©×§×•×œ ××•××—×™× ×—×™×¦×•× ×™×™×"
   - 2: ×’×•×£ ×—×™×¦×•× ×™ ××•×–×›×¨ ×œ×œ× ×¤×™×¨×•×˜
   - 3: ×’×•×£ ×‘×™×§×•×¨×ª ××•×’×“×¨ ×œ×œ× ×ª×”×œ×™×š
   - 4: ×’×•×£ ×—×™×¦×•× ×™ ×¢× ××•×¢×“ ×”×¢×¨×›×”
   - 5: ×‘×™×§×•×¨×ª ××¤×•×¨×˜×ª ×¢× ×ª×“×™×¨×•×ª ×•×¤×¨×¡×•×

7. ××©××‘×™× × ×“×¨×©×™× (0-5):
   - 0: ××™×Ÿ ××–×›×•×¨ ××©××‘×™×
   - 1: "×™×™×“×¨×© ×ª×§×¦×™×‘"
   - 2: ×¡×›×•× ××•×–×›×¨ ×œ×œ× ××§×•×¨
   - 3: ×¡×›×•× ×¢× ××§×•×¨ ×œ× ×‘×¨×•×¨
   - 4: ×ª×§×¦×™×‘ ×¢× ××§×•×¨ ×•×©×™××•×© ×¢×™×§×¨×™
   - 5: ×¤×™×¨×•×˜ ××œ× ×©×œ ×ª×§×¦×™×‘, ×›"×, ×•××§×•×¨×•×ª

8. ××¢×•×¨×‘×•×ª ×©×œ ××¡×¤×¨ ×“×¨×’×™× ×‘×ª×”×œ×™×š (0-5):
   - 0: ×¨×§ ×“×¨×’ ××—×“
   - 1: ×’×•×£ × ×•×¡×£ ×œ×”×ª×™×™×¢×¦×•×ª
   - 2: ×¨×©×™××ª ×“×¨×’×™× ×œ×œ× ×ª×™××•×
   - 3: ×“×¨×’×™× ×¢× ×¤×™×¨×•×˜ ×¢×§×¨×•× ×™
   - 4: ××¢×•×¨×‘×•×ª ××•×’×“×¨×ª ×©×œ ×›××” ×“×¨×’×™×
   - 5: ×ª×™××•×¨ ××œ× ×©×œ ×“×¨×’×™× ×•× ×”×œ×™ ×ª×™××•×

9. ××‘× ×” ×¡×¢×™×¤×™× ×•×—×œ×•×§×ª ×¢×‘×•×“×” ×‘×¨×•×¨×” (0-5):
   - 0: ×˜×§×¡×˜ ××‘×•×œ×’×Ÿ ×œ×œ× ×¡×¢×™×¤×™×
   - 1: ×¡×¢×™×¤×™× ×¢××•××™×
   - 2: ×—×œ×§ ××”×¡×¢×™×¤×™× ×¢× ××—×¨×™×•×ª
   - 3: ×¨×•×‘ ×”×¡×¢×™×¤×™× ×¢× ××—×¨×™×•×ª
   - 4: ×¡×¢×™×¤×™× ××¡×•×“×¨×™× ×¢× ××—×¨×™×•×ª
   - 5: ××‘× ×” ×‘×¨×•×¨ ×¢× ×¡×¢×™×¤×™×, ××—×¨×™×•×ª, ×•××‘× ×™ ×“×¨×š

10. ×× ×’× ×•×Ÿ ×™×™×©×•× ×‘×©×˜×— (0-5):
    - 0: ××™×Ÿ ××–×›×•×¨ ×œ×™×™×©×•×
    - 1: "× ×™×™×©× ×“×¨×š ×¨×©×•×™×•×ª"
    - 2: ×× ×’× ×•×Ÿ ×›×œ×œ×™ ×œ×œ× ×¤×™×¨×•×˜
    - 3: ×× ×’× ×•×Ÿ ×‘×¡×™×¡×™ ×¢× ×’×•×£ ××‘×¦×¢
    - 4: ×× ×’× ×•×Ÿ ×§×•× ×§×¨×˜×™ ×¢× ×™×—×™×“×•×ª ×œ×™×•×•×™
    - 5: ×ª×™××•×¨ ×©×œ× ×©×œ ××•×¤×Ÿ ×”×‘×™×¦×•×¢

11. ×’×•×¨× ××›×¨×™×¢ (0-5):
    - 0: ××™×Ÿ ×’×•×¨× ××›×¨×™×¢
    - 1: "×”×©×¨ ×¨×©××™ ×œ×”×—×œ×™×˜"
    - 2: "×•×¢×“×ª ×©×¨×™× ×ª×“×•×Ÿ"
    - 3: ×’×•×¨× ××›×¨×™×¢ ×œ×œ× ×ª×”×œ×™×š
    - 4: ×’×•×¨× ××›×¨×™×¢ ×‘×¨×•×¨
    - 5: ×’×•×¨× ××›×¨×™×¢ ×¢× ×ª×”×œ×™×š ××¤×•×¨×˜

12. ×©×•×ª×¤×•×ª ×‘×™×Ÿ ××’×–×¨×™×ª (0-5):
    - 0: ××™×Ÿ ×©×•×ª×¤×•×ª
    - 1: "× ×©×§×•×œ ×œ×©×ª×£"
    - 2: ××¨×’×•×Ÿ ××•×–×›×¨ ×œ×œ× ×ª×¤×§×™×“
    - 3: ××’×–×¨×™× ×©×•×ª×¤×™× ×œ×œ× ×× ×“×˜
    - 4: ×¤×™×¨×•×˜ ×¢×œ ×©×•×ª×¤×™× ×•××•×¤×Ÿ ×¢×‘×•×“×”
    - 5: ×©×™×ª×•×£ ××¤×•×¨×˜ ×¢× ×ª×¤×§×™×“×™× ×•××™××•×Ÿ

13. ××“×“×™ ×ª×•×¦××” ×•××¨×›×™×‘×™ ×”×¦×œ×—×” (0-5):
    - 0: ×¨×§ ×¤×¢×•×œ×•×ª ×œ×œ× ×™×¢×“×™×
    - 1: "× ×©××£ ×œ×©×™×¤×•×¨"
    - 2: ×™×¢×“ ×›×œ×œ×™ ×œ×œ× ××¡×¤×¨×™×
    - 3: ×™×¢×“ ××¡×¤×¨×™ ×œ×œ× ×–××Ÿ
    - 4: ×™×¢×“ ×›××•×ª×™ ×¢× ×–××Ÿ
    - 5: ×™×¢×“×™× ××¡×¤×¨×™×™× ×¢× ××ª×•×“×•×œ×•×’×™×”

**×—×©×•×‘**: ×× ×”××¡××š ××™× ×• ×”×—×œ×˜×ª ×××©×œ×” ××• ×˜×™×•×˜×” ×©×œ ×”×—×œ×˜×ª ×××©×œ×”, ××œ ×ª× ×ª×— ××•×ª×• ×œ×¤×™ ×”×§×¨×™×˜×¨×™×•× ×™×. ×‘××§×•× ×–××ª, ×”×—×–×¨:
{{
    "is_government_decision": false,
    "criteria_scores": [],
    "recommendations": [],
    "misuse_message": "××¦×˜×¢×¨, ×× ×™ ××™×•×¢×“ ××š ×•×¨×§ ×œ× ×™×ª×•×— ×˜×™×•×˜×•×ª ×©×œ ×”×—×œ×˜×•×ª ×××©×œ×”. ×”××¡××š ×©×”×¢×œ×™×ª × ×¨××” ×›××• [×¡×•×’ ×”××¡××š]. ×× ×‘×¨×¦×•× ×š ×œ× ×ª×— ×˜×™×•×˜×ª ×”×—×œ×˜×ª ×××©×œ×”, ×× × ×”×¢×œ×” ××• ×”×“×‘×§ ××ª ×”×˜×§×¡×˜ ×”××œ× ×©×œ ×”×˜×™×•×˜×”."
}}

×× ×–×• ×›×Ÿ ×”×—×œ×˜×ª ×××©×œ×”, ×”×—×–×¨ ××ª ×”×ª×©×•×‘×” ×‘×¤×•×¨××˜ JSON ×”×‘×:
{{
    "is_government_decision": true,
    "criteria_scores": [
        {{
            "criterion": "×©× ×”×§×¨×™×˜×¨×™×•×Ÿ",
            "score": 0-5,
            "explanation": "×”×¡×‘×¨ ×§×¦×¨",
            "reference_from_document": "×¦×™×˜×•×˜ ×¨×œ×•×•× ×˜×™ ××”××¡××š (×× ×§×™×™×)",
            "specific_improvement": "×”×¦×¢×” ×¡×¤×¦×™×¤×™×ª ×œ×©×™×¤×•×¨"
        }}
    ],
    "recommendations": ["×”××œ×¦×” 1", "×”××œ×¦×” 2", ...],
    "misuse_message": null
}}
"""
    return prompt

def detect_misuse(response_json: dict) -> tuple[bool, Optional[str]]:
    """Detect if the user is trying to misuse the bot"""
    if not response_json.get("is_government_decision", True):
        # Get the GPT's explanation if available
        gpt_message = response_json.get("misuse_message", "")
        
        # Extract what type of document GPT detected
        doc_type_match = re.search(r'× ×¨××” ×›××•\s*([^\.]+)', gpt_message)
        detected_type = doc_type_match.group(1) if doc_type_match else "××¡××š ×œ× ××–×•×”×”"
        
        # Create a more informative error message
        enhanced_message = f"""âš ï¸ **×©×™××•×© ×œ× ×ª×§×™×Ÿ**

××¦×˜×¢×¨, ×× ×™ ××™×•×¢×“ ××š ×•×¨×§ ×œ× ×™×ª×•×— ×˜×™×•×˜×•×ª ×©×œ ×”×—×œ×˜×•×ª ×××©×œ×”.

×”××¡××š ×©×”×¢×œ×™×ª × ×¨××” ×›××• **{detected_type}** ×•×œ× ××•×‘× ×” ×›×”×—×œ×˜×ª ×××©×œ×”.

×× ×‘×¨×¦×•× ×š ×œ× ×ª×— ×˜×™×•×˜×ª ×”×—×œ×˜×ª ×××©×œ×”, ×× × ×”×¢×œ×” ××• ×”×“×‘×§ ××ª ×”×˜×§×¡×˜ ×”××œ× ×©×œ ×”×˜×™×•×˜×”.

ğŸ’¡ **×˜×™×¤**: ×”×—×œ×˜×ª ×××©×œ×” ×¦×¨×™×›×” ×œ×›×œ×•×œ:
â€¢ ×›×•×ª×¨×ª ×¢× × ×•×©× ××“×™× ×™×•×ª
â€¢ ××–×›×•×¨ ×©×œ ××©×¨×“×™ ×××©×œ×” ××• ×©×¨×™×
â€¢ ×¡×¢×™×¤×™× ×”××ª××¨×™× ×¤×¢×•×œ×•×ª ×××©×œ×ª×™×•×ª
â€¢ ×©×¤×” ×¤×•×¨××œ×™×ª ×©×œ ××¡××š ×××©×œ×ª×™"""
        
        return True, enhanced_message
    return False, None

@app.post("/analyze", response_model=AnalyzeResponse)
async def analyze_decision(request: AnalyzeRequest):
    """Analyze a government decision draft against 13 criteria"""
    try:
        # Calculate document hash for tracking
        doc_hash = hashlib.md5(request.text.encode()).hexdigest()
        
        # Log the request with hash
        logger.info(f"Analyzing decision draft - text_length: {len(request.text)}, request_id: {request.requestId}, doc_hash: {doc_hash}")
        
        # Check cache for previous validation result
        cache_key = f"validation_{doc_hash}"
        cached_result = validation_cache.get(cache_key)
        if cached_result:
            cache_timestamp, is_valid, rejection_reason = cached_result
            if (datetime.utcnow() - cache_timestamp).total_seconds() < CACHE_EXPIRY_SECONDS:
                logger.info(f"Using cached validation result - doc_hash: {doc_hash}, is_valid: {is_valid}")
                if not is_valid:
                    return AnalyzeResponse(
                        criteria_scores=[],
                        recommendations=[],
                        model_used="cached",
                        misuse_detected=True,
                        misuse_message=rejection_reason
                    )
        
        # Always use GPT-4 for better accuracy in document classification
        model = "gpt-4o"
        
        # Create the evaluation prompt
        prompt = create_evaluation_prompt(request.text)
        
        # Call OpenAI API
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": """××ª×” ××•××—×” ×‘× ×™×ª×•×— ×”×—×œ×˜×•×ª ×××©×œ×” ×‘×™×©×¨××œ. 
×—×©×•×‘ ×××•×“: ××ª×” ×× ×ª×— ××š ×•×¨×§ ×˜×™×•×˜×•×ª ×©×œ ×”×—×œ×˜×•×ª ×××©×œ×”. 
×× ×”××¡××š ×©×”×•×’×© ××™× ×• ×”×—×œ×˜×ª ×××©×œ×” (×›××• ×›×¨×˜×™×¡ ×˜×™×¡×”, ×§×•×¨×•×ª ×—×™×™×, ×—×©×‘×•× ×™×ª ×•×›×•'), ×¢×œ×™×š ×œ×”×—×–×™×¨ is_government_decision: false.
×ª××™×“ ×”×—×–×¨ ×ª×©×•×‘×•×ª ×‘×¤×•×¨××˜ JSON ×ª×§×™×Ÿ."""},
                {"role": "user", "content": prompt}
            ],
            temperature=0.0,  # Set to 0 for consistent scoring
            max_tokens=3000
        )
        
        # Parse the response
        response_text = response.choices[0].message.content
        
        # Extract JSON from the response
        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
        if json_match:
            response_json = json.loads(json_match.group())
        else:
            logger.error(f"Failed to extract JSON from GPT response for doc_hash: {doc_hash}")
            raise ValueError("Failed to extract JSON from response")
        
        # Log the validation result
        is_gov_decision = response_json.get("is_government_decision", True)
        logger.info(f"Document validation - doc_hash: {doc_hash}, is_government_decision: {is_gov_decision}")
        
        # Check for misuse
        misuse_detected, misuse_message = detect_misuse(response_json)
        
        # Cache the validation result
        validation_cache[cache_key] = (datetime.utcnow(), not misuse_detected, misuse_message)
        
        if misuse_detected:
            logger.warning(f"Document rejected - doc_hash: {doc_hash}, reason: {misuse_message}")
            return AnalyzeResponse(
                criteria_scores=[],
                recommendations=[],
                model_used=model,
                misuse_detected=True,
                misuse_message=misuse_message
            )
        
        # Extract criteria scores
        criteria_scores = []
        for score_data in response_json.get("criteria_scores", []):
            criteria_scores.append(CriteriaScore(
                criterion=score_data["criterion"],
                score=score_data["score"],
                explanation=score_data["explanation"],
                reference_from_document=score_data.get("reference_from_document"),
                specific_improvement=score_data.get("specific_improvement")
            ))
        
        # Extract recommendations
        recommendations = response_json.get("recommendations", [])
        
        # Generate additional recommendations based on low scores
        for score in criteria_scores:
            if score.score <= 2:
                if score.criterion == "×œ×•×— ×–×× ×™× ××—×™×™×‘":
                    recommendations.append("×™×© ×œ×”×•×¡×™×£ ×ª××¨×™×›×™ ×™×¢×“ ××—×™×™×‘×™× ×œ×›×œ ××©×™××” ×¢×™×§×¨×™×ª ×‘×”×—×œ×˜×”")
                elif score.criterion == "×× ×’× ×•×Ÿ ×‘×™×§×•×¨×ª ×—×™×¦×•× ×™×ª":
                    recommendations.append("××•××œ×¥ ×œ×”×•×¡×™×£ ×× ×’× ×•×Ÿ ×‘×™×§×•×¨×ª ×—×™×¦×•× ×™×ª ×œ×•×•×“× ×™×™×©×•× ××¤×§×˜×™×‘×™")
                elif score.criterion == "××“×“×™ ×ª×•×¦××” ×•××¨×›×™×‘×™ ×”×¦×œ×—×”":
                    recommendations.append("×™×© ×œ×”×’×“×™×¨ ××“×“×™ ×”×¦×œ×—×” ×›××•×ª×™×™× ×•×‘×¨×•×¨×™× ×¢× ×™×¢×“×™× ××¡×¤×¨×™×™×")
        
        # Log token usage
        if hasattr(response, 'usage'):
            logger.info(f"Token usage - Model: {model}, Prompt: {response.usage.prompt_tokens}, "
                       f"Completion: {response.usage.completion_tokens}, "
                       f"Total: {response.usage.total_tokens}")
        
        return AnalyzeResponse(
            criteria_scores=criteria_scores,
            recommendations=recommendations[:5],  # Limit to top 5 recommendations
            model_used=model,
            misuse_detected=False
        )
        
    except json.JSONDecodeError as e:
        logger.error(f"JSON parsing error for doc_hash {doc_hash}: {str(e)}")
        # Try to be more resilient - assume it's a valid government document if parsing failed
        return AnalyzeResponse(
            criteria_scores=[],
            recommendations=["×œ× × ×™×ª×Ÿ ×œ×¤×¢× ×— ××ª ×ª×’×•×‘×ª ×”××¢×¨×›×ª. ×× × × ×¡×” ×©×•×‘."],
            model_used=model,
            misuse_detected=False
        )
    except Exception as e:
        logger.error(f"Error analyzing decision for doc_hash {doc_hash}: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "service": "Decision Guide Bot",
        "timestamp": datetime.utcnow().isoformat()
    }

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", "8018"))
    uvicorn.run(app, host="0.0.0.0", port=port)